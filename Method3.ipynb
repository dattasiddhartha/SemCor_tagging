{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import semcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor.sents()[7102]\n",
    "# semcor.tagged_sents(tag='both')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-418b078a8bea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msemcor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sem'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mexport1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"Lemma\\((.*?)\\)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msemcor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sem'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mexport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexport1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\util.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offsets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pieces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;31m# Iterate to the end of the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\util.py\u001b[0m in \u001b[0;36miterate_from\u001b[1;34m(self, start_tok)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# Get everything we can from this piece.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpiece\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_tok\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\util.py\u001b[0m in \u001b[0;36miterate_from\u001b[1;34m(self, start_tok)\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[0;32m    298\u001b[0m                 \u001b[1;34m'block reader %s() should return list or tuple.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\xmldocs.py\u001b[0m in \u001b[0;36mread_block\u001b[1;34m(self, stream, tagspec, elt_handler)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                   elt.encode('ascii', 'xmlcharrefreplace')),\n\u001b[0;32m    391\u001b[0m                             context)\n\u001b[1;32m--> 392\u001b[1;33m                 for (elt, context) in elts]\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\xmldocs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                   elt.encode('ascii', 'xmlcharrefreplace')),\n\u001b[0;32m    391\u001b[0m                             context)\n\u001b[1;32m--> 392\u001b[1;33m                 for (elt, context) in elts]\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36mhandle_elt\u001b[1;34m(self, elt, context)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_elt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36mhandle_sent\u001b[1;34m(self, elt)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'wf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'punc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 \u001b[0mitm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unit\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                     \u001b[0msent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36mhandle_word\u001b[1;34m(self, elt)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSemcorCorpusReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pos_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sem_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wordnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36m_word\u001b[1;34m(xmlword, unit, pos_tag, sem_tag, wordnet)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msensenum\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                         \u001b[0msense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_from_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msense_key\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Lemma object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                         \u001b[1;31m# cannot retrieve the wordnet.Lemma object. possible reasons:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36mlemma_from_key\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \u001b[1;31m# Find the synset for the lemma.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1273\u001b[1;33m         \u001b[0msynset_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_binary_search_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key_synset_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msynset_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mWordNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No synset found for key %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\util.py\u001b[0m in \u001b[0;36mbinary_search_file\u001b[1;34m(file, key, cache, cacheDepth)\u001b[0m\n\u001b[0;32m    614\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmiddle\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                 \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mtell\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rewind_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_char_seek_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rewind_numchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m         \u001b[0mfilepos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[1;31m# Sanity check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# semcor.tagged_sents(tag='sem')[1]#[3].label()\n",
    "import re\n",
    "import pandas as pd\n",
    "# export1=re.findall(r\"Lemma\\((.*?)\\)\", str(semcor.tagged_sents(tag='sem')[0:99]))\n",
    "# export2=re.findall(r\"Lemma\\((.*?)\\)\", str(semcor.tagged_sents(tag='sem')[100:199]))\n",
    "\n",
    "i=0\n",
    "while i < len(semcor.tagged_sents(tag='sem')):\n",
    "    export1=re.findall(r\"Lemma\\((.*?)\\)\", str(semcor.tagged_sents(tag='sem')[i:i+99]))\n",
    "    export=export1+export\n",
    "    i+=100\n",
    "\n",
    "export_df=pd.DataFrame(export)\n",
    "export_df.to_csv(\"sense_export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'group.n.01.group'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'state.v.01.say'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'friday.n.01.Friday'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'probe.n.01.investigation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'atlanta.n.01.Atlanta'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'late.s.03.recent'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'primary.n.01.primary_election'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'produce.v.04.produce'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'evidence.n.01.evidence'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'abnormality.n.04.irregularity'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'happen.v.01.take_place'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'jury.n.01.jury'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'far.r.02.far'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'state.v.01.say'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'term.n.02.term'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'end.n.02.end'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'presentment.n.01.presentment'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'group.n.01.group'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'own.v.01.have'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'overall.s.02.overall'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>'mission.n.03.charge'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'election.n.01.election'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'deserve.v.01.deserve'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'praise.n.01.praise'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'thanks.n.01.thanks'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'location.n.01.location'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'manner.n.01.manner'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'election.n.01.election'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'conduct.v.01.conduct'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>'september.n.01.September'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>'send.v.01.send'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>'fail.v.02.fail'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>'bunt.n.01.bunt'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>'attempt.n.01.attempt'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>'pop.v.02.pop'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>'grass.n.01.grass'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>'back.r.02.back'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>'short.n.01.short'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>'bat.v.01.bat'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>'fan.v.01.fan'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>'foul.v.01.foul'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>'two.s.01.two'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>'pitch.n.02.pitch'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>'bounce_out.v.01.bounce_out'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>'aggressively.r.01.sharply'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>'person.n.01.person'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>'second_base.n.02.second'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>'end.v.02.end'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>'two.s.01.2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>'hour.n.01.hour'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>'twenty-seven.s.01.27'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>'minute.n.01.minute'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>'contest.n.01.contest'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2223 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "0                  'group.n.01.group'\n",
       "1                    'state.v.01.say'\n",
       "2                'friday.n.01.Friday'\n",
       "3          'probe.n.01.investigation'\n",
       "4              'atlanta.n.01.Atlanta'\n",
       "5                  'late.s.03.recent'\n",
       "6     'primary.n.01.primary_election'\n",
       "7              'produce.v.04.produce'\n",
       "8            'evidence.n.01.evidence'\n",
       "9     'abnormality.n.04.irregularity'\n",
       "10           'happen.v.01.take_place'\n",
       "11                   'jury.n.01.jury'\n",
       "12                     'far.r.02.far'\n",
       "13                   'state.v.01.say'\n",
       "14                   'term.n.02.term'\n",
       "15                     'end.n.02.end'\n",
       "16     'presentment.n.01.presentment'\n",
       "17                 'group.n.01.group'\n",
       "18                    'own.v.01.have'\n",
       "19             'overall.s.02.overall'\n",
       "20              'mission.n.03.charge'\n",
       "21           'election.n.01.election'\n",
       "22             'deserve.v.01.deserve'\n",
       "23               'praise.n.01.praise'\n",
       "24               'thanks.n.01.thanks'\n",
       "25           'location.n.01.location'\n",
       "26               'manner.n.01.manner'\n",
       "27           'election.n.01.election'\n",
       "28             'conduct.v.01.conduct'\n",
       "29         'september.n.01.September'\n",
       "...                               ...\n",
       "2193             'person.n.01.person'\n",
       "2194                 'send.v.01.send'\n",
       "2195             'person.n.01.person'\n",
       "2196                 'fail.v.02.fail'\n",
       "2197                 'bunt.n.01.bunt'\n",
       "2198           'attempt.n.01.attempt'\n",
       "2199                   'pop.v.02.pop'\n",
       "2200             'person.n.01.person'\n",
       "2201               'grass.n.01.grass'\n",
       "2202                 'back.r.02.back'\n",
       "2203               'short.n.01.short'\n",
       "2204             'person.n.01.person'\n",
       "2205                   'bat.v.01.bat'\n",
       "2206             'person.n.01.person'\n",
       "2207                   'fan.v.01.fan'\n",
       "2208                 'foul.v.01.foul'\n",
       "2209                   'two.s.01.two'\n",
       "2210               'pitch.n.02.pitch'\n",
       "2211             'person.n.01.person'\n",
       "2212             'person.n.01.person'\n",
       "2213     'bounce_out.v.01.bounce_out'\n",
       "2214      'aggressively.r.01.sharply'\n",
       "2215             'person.n.01.person'\n",
       "2216        'second_base.n.02.second'\n",
       "2217                   'end.v.02.end'\n",
       "2218                     'two.s.01.2'\n",
       "2219                 'hour.n.01.hour'\n",
       "2220           'twenty-seven.s.01.27'\n",
       "2221             'minute.n.01.minute'\n",
       "2222           'contest.n.01.contest'\n",
       "\n",
       "[2223 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df\n",
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"emma('group.n.01.group\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mystring=str(semcor.tagged_sents(tag='both')[0:2])#.replace('\\','')\n",
    "#                                                     #.split(\"Lemma('\")[1].split(\"')\")[0]\n",
    "# # s[s.find(\"Lemma(\\'\")+1:s.find(\"\\')\")]\n",
    "# s\n",
    "# start = mystring.find( 'Lemma(\\'' )\n",
    "# end = mystring.find( '\\')' )\n",
    "# if start != -1 and end != -1:\n",
    "#     result = mystring[start+1:end]\n",
    "# # result\n",
    "# # s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"]\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']['the']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']['the'](Lemma('election.n.01.election') election)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']['the'](Lemma('election.n.01.election') election)[',']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']['the'](Lemma('election.n.01.election') election)[',']['``']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']['the'](Lemma('election.n.01.election') election)[',']['``'](Lemma('deserve.v.01.deserve') deserves)\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']['the'](Lemma('election.n.01.election') election)[',']['``'](Lemma('deserve.v.01.deserve') deserves)['the']\n",
      "['The'](Lemma('group.n.01.group') (NE Fulton County Grand Jury))(Lemma('state.v.01.say') said)(Lemma('friday.n.01.Friday') Friday)['an'](Lemma('probe.n.01.investigation') investigation)['of'](Lemma('atlanta.n.01.Atlanta') Atlanta)[\"'s\"](Lemma('late.s.03.recent') recent)(Lemma('primary.n.01.primary_election') primary election)(Lemma('produce.v.04.produce') produced)['``']['no'](Lemma('evidence.n.01.evidence') evidence)[\"''\"]['that']['any'](Lemma('abnormality.n.04.irregularity') irregularities)(Lemma('happen.v.01.take_place') took place)['.']['The'](Lemma('jury.n.01.jury') jury)(Lemma('far.r.02.far') further)(Lemma('state.v.01.say') said)['in'](Lemma('term.n.02.term') term)(Lemma('end.n.02.end') end)(Lemma('presentment.n.01.presentment') presentments)['that']['the'](Lemma('group.n.01.group') (NE City Executive Committee))[',']['which'](Lemma('own.v.01.have') had)(Lemma('overall.s.02.overall') over-all)(Lemma('mission.n.03.charge') charge)['of']['the'](Lemma('election.n.01.election') election)[',']['``'](Lemma('deserve.v.01.deserve') deserves)['the'](Lemma('praise.n.01.praise') praise)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'infile' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\xmldocs.py\u001b[0m in \u001b[0;36m_detect_encoding\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[0minfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_zipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m         \u001b[1;31m# Ensure that _fileRefCnt needs to be set for Python2and3 compatible code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\zipfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, name, pwd)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[1;34m\"\"\"Return file bytes (as a string) for name.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[0;32m   1367\u001b[0m             \u001b[1;31m# Skip the file header:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m             \u001b[0mfheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzef_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msizeFileHeader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfheader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msizeFileHeader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\zipfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-95cac32b74ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msemcor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sem'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#         indexlist.append(i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0msense_string\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msemcor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sem'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.label())#.replace(\"Lemma\",\"\")+','\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msense_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36mtagged_sents\u001b[1;34m(self, fileids, tag)\u001b[0m\n\u001b[0;32m     88\u001b[0m             Punctuation tokens have `None` for their part of speech tag.)\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'chunk'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'sem'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'pos'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbracket_sent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msem_tag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36m_items\u001b[1;34m(self, fileids, unit, bracket_sent, pos_tag, sem_tag)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSemcorWordView\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         return concat([_(fileid, unit, bracket_sent, pos_tag, sem_tag, self._wordnet)\n\u001b[1;32m--> 100\u001b[1;33m                        for fileid in self.abspaths(fileids)])\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbracket_sent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msem_tag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSemcorWordView\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         return concat([_(fileid, unit, bracket_sent, pos_tag, sem_tag, self._wordnet)\n\u001b[1;32m--> 100\u001b[1;33m                        for fileid in self.abspaths(fileids)])\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbracket_sent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msem_tag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fileid, unit, bracket_sent, pos_tag, sem_tag, wordnet)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wordnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mXMLCorpusView\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_elt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\xmldocs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fileid, tagspec, elt_handler)\u001b[0m\n\u001b[0;32m    153\u001b[0m            been closed.\"\"\"\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_detect_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0mStreamBackedCorpusView\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\xmldocs.py\u001b[0m in \u001b[0;36m_detect_encoding\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'infile' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# senselist=[]\n",
    "# indexlist=[]\n",
    "sense_string=str()\n",
    "for i in range(len(semcor.tagged_sents(tag='sem')[0:10])):\n",
    "    for j in range(len(semcor.tagged_sents(tag='sem')[i])):\n",
    "#         indexlist.append(i)\n",
    "        sense_string+=str(semcor.tagged_sents(tag='sem')[i][j])#.label())#.replace(\"Lemma\",\"\")+','\n",
    "        print(sense_string)\n",
    "\n",
    "# only keep strings that follow pattern Lemma(\"   \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'group.n.01.group'\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_string[sense_string.find(\"(\")+1:sense_string.find(\")\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DT,('group.n.01.group'),('state.v.01.say'),('friday.n.01.Friday'),DT,('probe.n.01.investigation'),IN,('atlanta.n.01.Atlanta'),POS,('late.s.03.recent'),('primary.n.01.primary_election'),('produce.v.04.produce'),None,DT,('evidence.n.01.evidence'),None,IN,DT,('abnormality.n.04.irregularity'),('happen.v.01.take_place'),None,\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(semcor.tagged_sents(tag='both'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# tree=semcor.tagged_sents(tag='both')[1][1].label()\n",
    "# print(tree)\n",
    "# words = [ w for w, t in semcor.tagged_sents(tag='both')[1].leaves() ]\n",
    "# re.findall(r\"([^.]*?'state.v.01.say'[^.]*\\.)\",str(semcor.tagged_sents(tag='both')[1]))\n",
    "# for subtree in tree.subtrees():\n",
    "#      if subtree.label() == 'Lemma':\n",
    "#             print(subtree.leaves())\n",
    "# [word for word,pos in tree.pos() if pos=='Lemma']\n",
    "# list(tree.subtrees(filter=lambda x: x.node=='Lemma'))\n",
    "senselist=[]\n",
    "indexlist=[]\n",
    "for i in range(len(semcor.tagged_sents(tag='both')[0:10])):\n",
    "    for j in range(len(semcor.tagged_sents(tag='both')[i])):\n",
    "        indexlist.append(i)\n",
    "        senselist.append(semcor.tagged_sents(tag='both')[i][j].label())\n",
    "        print(senselist, indexlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-17-9a02a29e0bbe>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-9a02a29e0bbe>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    for i.label() in semcor.tagged_sents(tag='both')[1]:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "# test=[item for sublist in l for item in semcor.sents()[0:5]]\n",
    "flat_list=[]\n",
    "# for i in semcor.sents()[0:10]:\n",
    "for i in semcor.tagged_sents(tag='both')[0:10]:\n",
    "    flat_list.append(i)\n",
    "# string = str(semcor.sents()[0:5])\n",
    "string = str(flat_list)\n",
    "\n",
    "DICT = {}\n",
    "\n",
    "LIST  =  string.split('.')\n",
    "\n",
    "WORDS = list(set(string.lower().replace('.',\"\").split()))\n",
    "\n",
    "LIST = [set((x.lower()).split()) for x in LIST]\n",
    "\n",
    "for i in range(len(LIST)):\n",
    "    for item in WORDS:\n",
    "        if item in LIST[i]:\n",
    "            DICT.setdefault(item, []).append(i)\n",
    "print(DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'place',\": [0], \"'friday',\": [0], \"'primary',\": [0, 2], \"'said',\": [0, 1, 4, 5, 7, 8, 9], \"'atlanta',\": [0, 1, 7], \"'``',\": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10], \"'produced',\": [0], \"'took',\": [0], \"'fulton',\": [0, 2, 6, 7], \"'an',\": [0], \"'no',\": [0], \"'evidence',\": [0], \"'jury',\": [0, 1, 2, 4, 5, 7, 8, 9], \"'investigation',\": [0], \"'any',\": [0], '\"\\'\\'\",': [0, 1, 2, 4, 5, 6, 7, 8, 9, 10], \"'of',\": [0, 1, 2, 4, 5, 6, 7, 8, 9], \"[['the',\": [0], \"'election',\": [0, 1, 4, 5], \"'irregularities',\": [0, 2], '\"\\'s\",': [0, 5], \"'county',\": [0, 7], \"'grand',\": [0, 7], \"'recent',\": [0], \"'that',\": [0, 1, 5, 6, 10], \"'conducted',\": [1], \"'had',\": [1, 2], \"'term',\": [1, 2], \"'which',\": [1, 2, 7], \"'end',\": [1, 6], \"['the',\": [1, 2, 5, 7, 9], \"'presentments',\": [1], \"',',\": [1, 4, 7, 8, 9], \"'in',\": [1, 2, 4, 9], \"'deserves',\": [1], \"'and',\": [1, 4, 5, 6, 7, 8], \"'executive',\": [1], \"'was',\": [1, 2, 4], \"'for',\": [1], \"'praise',\": [1], \"'city',\": [1, 4, 9, 10], \"'the',\": [1, 2, 4, 6, 7, 8, 9, 10], \"'further',\": [1], \"'manner',\": [1], \"'charge',\": [1], \"'over-all',\": [1], \"'thanks',\": [1], \"'committee',\": [1], \"'reports',\": [2, 4], \"'investigate',\": [2], \"'durwood',\": [2], \"'superior',\": [2], \"'allen',\": [2], \"'by',\": [2], \"'been',\": [2], \"'judge',\": [2], \"'possible',\": [2], \"'october',\": [2], \"'mayor-nominate',\": [2], \"'hard-fought',\": [2], \"'pye',\": [2], \"'ivan',\": [2], \"'to',\": [2, 6, 7, 8, 10], \"'september',\": [2], \"'court',\": [2], \"'won',\": [2], \"'charged',\": [2], \"'widespread',\": [4], \"'number',\": [4, 7], \"'received',\": [4], \"'such',\": [4], \"['``',\": [4], \"'only',\": [4], \"'handful',\": [4], \"'considering',\": [4], \"'size',\": [4], \"'a',\": [4, 7, 9], \"'voters',\": [4], \"'interest',\": [4, 7], \"'this',\": [4, 10], \"'relative',\": [4], \"'it',\": [5, 7, 8], \"'georgia',\": [5], \"'many',\": [5], \"'laws',\": [5, 6], \"'or',\": [5], \"'registration',\": [5], \"'find',\": [5], \"'did',\": [5], \"'are',\": [5, 7], \"'inadequate',\": [5], \"'ambiguous',\": [5], \"'outmoded',\": [5], \"'often',\": [5], \"'legislators',\": [6], \"'act',\": [6], \"'revised',\": [6], \"'improving',\": [6], \"'them',\": [6, 7], \"'have',\": [6], \"'studied',\": [6], \"'these',\": [6, 8], \"'modernizing',\": [6], \"'recommended',\": [6], \"['it',\": [6, 10], \"'on',\": [7], \"'purchasing',\": [7, 9], \"'topics',\": [7], \"'generally',\": [7], \"'practices',\": [7], \"'other',\": [7], \"'departments',\": [7], \"'among',\": [7], \"'operated',\": [7], \"'both',\": [7], \"'follow',\": [7], \"'governments',\": [7], \"'well',\": [7], \"'accepted',\": [7], \"'inure',\": [7], \"'commented',\": [7], \"'best',\": [7], \"['however',\": [8], \"'administration',\": [8], \"'two',\": [8], \"'combined',\": [8], \"'cost',\": [8], \"'should',\": [8], \"'offices',\": [8], \"'efficiency',\": [8], \"'believes',\": [8], \"'reduce',\": [8], \"'achieve',\": [8], \"'be',\": [8], \"'greater',\": [8], \"'clerical',\": [9], \"'department',\": [9], \"'as',\": [9], \"'is',\": [9], \"'experienced',\": [9], \"'personnel',\": [9], \"'lacking',\": [9], \"'policies',\": [9], \"'result',\": [9], \"'take',\": [10], \"'remedy',\": [10], \"'urged',\": [10], \"'problem',\": [10], \"'steps',\": [10]}\n"
     ]
    }
   ],
   "source": [
    "# test=[item for sublist in l for item in semcor.sents()[0:5]]\n",
    "flat_list=[]\n",
    "for i in semcor.sents()[0:10]:\n",
    "# for i in semcor.sents():\n",
    "    flat_list.append(i)\n",
    "# string = str(semcor.sents()[0:5])\n",
    "string = str(flat_list)\n",
    "\n",
    "DICT = {}\n",
    "\n",
    "LIST  =  string.split('.')\n",
    "\n",
    "WORDS = list(set(string.lower().replace('.',\"\").split()))\n",
    "\n",
    "LIST = [set((x.lower()).split()) for x in LIST]\n",
    "\n",
    "for i in range(len(LIST)):\n",
    "    for item in WORDS:\n",
    "        if item in LIST[i]:\n",
    "            DICT.setdefault(item, []).append(i)\n",
    "print(DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semcor.sents()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe=pd.read_csv(\"export_file.csv\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41722, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.iloc[1,1]\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=dataframe[1:]\n",
    "import ast\n",
    "# [n for n in ast.literal_eval(dataframe.iloc[1,1])]\n",
    "listlist=[]\n",
    "import itertools\n",
    "for i in range(len(dataframe)):\n",
    "    listlist.append([n for n in ast.literal_eval(dataframe.iloc[i,1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dataframe['list_correct']=listlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>list_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'psychology',</td>\n",
       "      <td>[2300, 2337, 2786, 13505, 14583, 14707, 25248,...</td>\n",
       "      <td>[2300, 2337, 2786, 13505, 14583, 14707, 25248,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'entrant',</td>\n",
       "      <td>[3501, 22709]</td>\n",
       "      <td>[3501, 22709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'disfavor',</td>\n",
       "      <td>[31555]</td>\n",
       "      <td>[31555]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['attorney',</td>\n",
       "      <td>[14514, 21286]</td>\n",
       "      <td>[14514, 21286]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'visualization',</td>\n",
       "      <td>[1210]</td>\n",
       "      <td>[1210]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'flamed',</td>\n",
       "      <td>[7945]</td>\n",
       "      <td>[7945]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'aiding',</td>\n",
       "      <td>[15572, 19590, 21151, 21441, 23325, 23512]</td>\n",
       "      <td>[15572, 19590, 21151, 21441, 23325, 23512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'symphony',</td>\n",
       "      <td>[935, 1089, 1999, 7504, 11491, 11494, 11498, 1...</td>\n",
       "      <td>[935, 1089, 1999, 7504, 11491, 11494, 11498, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'1488',</td>\n",
       "      <td>[29364]</td>\n",
       "      <td>[29364]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'lilacs',</td>\n",
       "      <td>[13822, 13850]</td>\n",
       "      <td>[13822, 13850]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['workers',</td>\n",
       "      <td>[12086]</td>\n",
       "      <td>[12086]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['bmews',</td>\n",
       "      <td>[33698]</td>\n",
       "      <td>[33698]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'illinois',</td>\n",
       "      <td>[356, 12746, 12747, 15031, 16708, 21269, 21402...</td>\n",
       "      <td>[356, 12746, 12747, 15031, 16708, 21269, 21402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'machines',</td>\n",
       "      <td>[2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...</td>\n",
       "      <td>[2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'toot',</td>\n",
       "      <td>[9629, 28659]</td>\n",
       "      <td>[9629, 28659]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'sokolov',</td>\n",
       "      <td>[28696]</td>\n",
       "      <td>[28696]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'alertly',</td>\n",
       "      <td>[18830]</td>\n",
       "      <td>[18830]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'lucretius',</td>\n",
       "      <td>[14994]</td>\n",
       "      <td>[14994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'glob-flakes',</td>\n",
       "      <td>[7304]</td>\n",
       "      <td>[7304]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'cuffs',</td>\n",
       "      <td>[9609, 36187]</td>\n",
       "      <td>[9609, 36187]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['sections',</td>\n",
       "      <td>[4678, 4690, 4694, 4717]</td>\n",
       "      <td>[4678, 4690, 4694, 4717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'occupy',</td>\n",
       "      <td>[2355, 3420, 8839, 11590, 13258, 13691, 28328,...</td>\n",
       "      <td>[2355, 3420, 8839, 11590, 13258, 13691, 28328,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'accessions',</td>\n",
       "      <td>[35184]</td>\n",
       "      <td>[35184]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'imaginary',</td>\n",
       "      <td>[5915, 5920, 6559, 9271, 10064, 10066, 14908, ...</td>\n",
       "      <td>[5915, 5920, 6559, 9271, 10064, 10066, 14908, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'absinthe',</td>\n",
       "      <td>[31512]</td>\n",
       "      <td>[31512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'souci',</td>\n",
       "      <td>[7388]</td>\n",
       "      <td>[7388]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['prior',</td>\n",
       "      <td>[341, 2732, 15393, 15394, 22886, 34721, 35375]</td>\n",
       "      <td>[341, 2732, 15393, 15394, 22886, 34721, 35375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'double-bogeyed',</td>\n",
       "      <td>[24467]</td>\n",
       "      <td>[24467]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'progresses',</td>\n",
       "      <td>[3063, 6248, 31054, 31056, 33495]</td>\n",
       "      <td>[3063, 6248, 31054, 31056, 33495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>'autistic',</td>\n",
       "      <td>[26379, 26387, 26390, 26392, 26394, 26396, 264...</td>\n",
       "      <td>[26379, 26387, 26390, 26392, 26394, 26396, 264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41691</th>\n",
       "      <td>'encroachment',</td>\n",
       "      <td>[2089, 12119, 20228, 34414, 35452]</td>\n",
       "      <td>[2089, 12119, 20228, 34414, 35452]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41692</th>\n",
       "      <td>'potentiality',</td>\n",
       "      <td>[1678]</td>\n",
       "      <td>[1678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41693</th>\n",
       "      <td>'filter',</td>\n",
       "      <td>[3967, 4685, 4686, 4687, 6267, 32472]</td>\n",
       "      <td>[3967, 4685, 4686, 4687, 6267, 32472]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41694</th>\n",
       "      <td>'canals',</td>\n",
       "      <td>[33913]</td>\n",
       "      <td>[33913]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>'tragically',</td>\n",
       "      <td>[11379]</td>\n",
       "      <td>[11379]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>'cieca',</td>\n",
       "      <td>[28301]</td>\n",
       "      <td>[28301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>'allot',</td>\n",
       "      <td>[31798]</td>\n",
       "      <td>[31798]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>'protease',</td>\n",
       "      <td>[4433]</td>\n",
       "      <td>[4433]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>'misleads',</td>\n",
       "      <td>[29008]</td>\n",
       "      <td>[29008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41700</th>\n",
       "      <td>'arcaded',</td>\n",
       "      <td>[33952]</td>\n",
       "      <td>[33952]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41701</th>\n",
       "      <td>'proviso',</td>\n",
       "      <td>[17771, 30032, 35354]</td>\n",
       "      <td>[17771, 30032, 35354]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41702</th>\n",
       "      <td>'charts',</td>\n",
       "      <td>[6223, 13048, 13090, 28938, 32086, 33732]</td>\n",
       "      <td>[6223, 13048, 13090, 28938, 32086, 33732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41703</th>\n",
       "      <td>['digby',</td>\n",
       "      <td>[10471, 10481, 10494]</td>\n",
       "      <td>[10471, 10481, 10494]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41704</th>\n",
       "      <td>'koop',</td>\n",
       "      <td>[5799]</td>\n",
       "      <td>[5799]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41705</th>\n",
       "      <td>'bronze',</td>\n",
       "      <td>[5608, 8365, 26430, 29107, 29745, 32101]</td>\n",
       "      <td>[5608, 8365, 26430, 29107, 29745, 32101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41706</th>\n",
       "      <td>'tracers',</td>\n",
       "      <td>[32742]</td>\n",
       "      <td>[32742]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41707</th>\n",
       "      <td>'schelling',</td>\n",
       "      <td>[11768, 14988]</td>\n",
       "      <td>[11768, 14988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41708</th>\n",
       "      <td>'appearances',</td>\n",
       "      <td>[10222, 21423, 22973, 23743, 28433, 28534, 288...</td>\n",
       "      <td>[10222, 21423, 22973, 23743, 28433, 28534, 288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41709</th>\n",
       "      <td>'acclaimed',</td>\n",
       "      <td>[663, 20501, 28528]</td>\n",
       "      <td>[663, 20501, 28528]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41710</th>\n",
       "      <td>'creditable',</td>\n",
       "      <td>[11388, 22237]</td>\n",
       "      <td>[11388, 22237]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41711</th>\n",
       "      <td>'blaine',</td>\n",
       "      <td>[17627, 21215]</td>\n",
       "      <td>[17627, 21215]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41712</th>\n",
       "      <td>'volume',</td>\n",
       "      <td>[252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...</td>\n",
       "      <td>[252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41713</th>\n",
       "      <td>'recalling',</td>\n",
       "      <td>[2330, 13923, 26586, 28177, 34236, 38583]</td>\n",
       "      <td>[2330, 13923, 26586, 28177, 34236, 38583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41714</th>\n",
       "      <td>'booty',</td>\n",
       "      <td>[12901, 37725, 37754]</td>\n",
       "      <td>[12901, 37725, 37754]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41715</th>\n",
       "      <td>['agnese',</td>\n",
       "      <td>[19970, 19989]</td>\n",
       "      <td>[19970, 19989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41716</th>\n",
       "      <td>'admirably',</td>\n",
       "      <td>[11179, 28081]</td>\n",
       "      <td>[11179, 28081]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41717</th>\n",
       "      <td>['setting',</td>\n",
       "      <td>[18908]</td>\n",
       "      <td>[18908]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41718</th>\n",
       "      <td>'lumps',</td>\n",
       "      <td>[4038]</td>\n",
       "      <td>[4038]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41719</th>\n",
       "      <td>'dialyzed',</td>\n",
       "      <td>[3941, 3974, 4023, 4666]</td>\n",
       "      <td>[3941, 3974, 4023, 4666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41720</th>\n",
       "      <td>'officielle',</td>\n",
       "      <td>[35509]</td>\n",
       "      <td>[35509]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                                                  1  \\\n",
       "0          'psychology',  [2300, 2337, 2786, 13505, 14583, 14707, 25248,...   \n",
       "1             'entrant',                                      [3501, 22709]   \n",
       "2            'disfavor',                                            [31555]   \n",
       "3           ['attorney',                                     [14514, 21286]   \n",
       "4       'visualization',                                             [1210]   \n",
       "5              'flamed',                                             [7945]   \n",
       "6              'aiding',         [15572, 19590, 21151, 21441, 23325, 23512]   \n",
       "7            'symphony',  [935, 1089, 1999, 7504, 11491, 11494, 11498, 1...   \n",
       "8                '1488',                                            [29364]   \n",
       "9              'lilacs',                                     [13822, 13850]   \n",
       "10           ['workers',                                            [12086]   \n",
       "11             ['bmews',                                            [33698]   \n",
       "12           'illinois',  [356, 12746, 12747, 15031, 16708, 21269, 21402...   \n",
       "13           'machines',  [2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...   \n",
       "14               'toot',                                      [9629, 28659]   \n",
       "15            'sokolov',                                            [28696]   \n",
       "16            'alertly',                                            [18830]   \n",
       "17          'lucretius',                                            [14994]   \n",
       "18        'glob-flakes',                                             [7304]   \n",
       "19              'cuffs',                                      [9609, 36187]   \n",
       "20          ['sections',                           [4678, 4690, 4694, 4717]   \n",
       "21             'occupy',  [2355, 3420, 8839, 11590, 13258, 13691, 28328,...   \n",
       "22         'accessions',                                            [35184]   \n",
       "23          'imaginary',  [5915, 5920, 6559, 9271, 10064, 10066, 14908, ...   \n",
       "24           'absinthe',                                            [31512]   \n",
       "25              'souci',                                             [7388]   \n",
       "26             ['prior',     [341, 2732, 15393, 15394, 22886, 34721, 35375]   \n",
       "27     'double-bogeyed',                                            [24467]   \n",
       "28         'progresses',                  [3063, 6248, 31054, 31056, 33495]   \n",
       "29           'autistic',  [26379, 26387, 26390, 26392, 26394, 26396, 264...   \n",
       "...                  ...                                                ...   \n",
       "41691    'encroachment',                 [2089, 12119, 20228, 34414, 35452]   \n",
       "41692    'potentiality',                                             [1678]   \n",
       "41693          'filter',              [3967, 4685, 4686, 4687, 6267, 32472]   \n",
       "41694          'canals',                                            [33913]   \n",
       "41695      'tragically',                                            [11379]   \n",
       "41696           'cieca',                                            [28301]   \n",
       "41697           'allot',                                            [31798]   \n",
       "41698        'protease',                                             [4433]   \n",
       "41699        'misleads',                                            [29008]   \n",
       "41700         'arcaded',                                            [33952]   \n",
       "41701         'proviso',                              [17771, 30032, 35354]   \n",
       "41702          'charts',          [6223, 13048, 13090, 28938, 32086, 33732]   \n",
       "41703          ['digby',                              [10471, 10481, 10494]   \n",
       "41704            'koop',                                             [5799]   \n",
       "41705          'bronze',           [5608, 8365, 26430, 29107, 29745, 32101]   \n",
       "41706         'tracers',                                            [32742]   \n",
       "41707       'schelling',                                     [11768, 14988]   \n",
       "41708     'appearances',  [10222, 21423, 22973, 23743, 28433, 28534, 288...   \n",
       "41709       'acclaimed',                                [663, 20501, 28528]   \n",
       "41710      'creditable',                                     [11388, 22237]   \n",
       "41711          'blaine',                                     [17627, 21215]   \n",
       "41712          'volume',  [252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...   \n",
       "41713       'recalling',          [2330, 13923, 26586, 28177, 34236, 38583]   \n",
       "41714           'booty',                              [12901, 37725, 37754]   \n",
       "41715         ['agnese',                                     [19970, 19989]   \n",
       "41716       'admirably',                                     [11179, 28081]   \n",
       "41717        ['setting',                                            [18908]   \n",
       "41718           'lumps',                                             [4038]   \n",
       "41719        'dialyzed',                           [3941, 3974, 4023, 4666]   \n",
       "41720      'officielle',                                            [35509]   \n",
       "\n",
       "                                            list_correct  \n",
       "0      [2300, 2337, 2786, 13505, 14583, 14707, 25248,...  \n",
       "1                                          [3501, 22709]  \n",
       "2                                                [31555]  \n",
       "3                                         [14514, 21286]  \n",
       "4                                                 [1210]  \n",
       "5                                                 [7945]  \n",
       "6             [15572, 19590, 21151, 21441, 23325, 23512]  \n",
       "7      [935, 1089, 1999, 7504, 11491, 11494, 11498, 1...  \n",
       "8                                                [29364]  \n",
       "9                                         [13822, 13850]  \n",
       "10                                               [12086]  \n",
       "11                                               [33698]  \n",
       "12     [356, 12746, 12747, 15031, 16708, 21269, 21402...  \n",
       "13     [2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...  \n",
       "14                                         [9629, 28659]  \n",
       "15                                               [28696]  \n",
       "16                                               [18830]  \n",
       "17                                               [14994]  \n",
       "18                                                [7304]  \n",
       "19                                         [9609, 36187]  \n",
       "20                              [4678, 4690, 4694, 4717]  \n",
       "21     [2355, 3420, 8839, 11590, 13258, 13691, 28328,...  \n",
       "22                                               [35184]  \n",
       "23     [5915, 5920, 6559, 9271, 10064, 10066, 14908, ...  \n",
       "24                                               [31512]  \n",
       "25                                                [7388]  \n",
       "26        [341, 2732, 15393, 15394, 22886, 34721, 35375]  \n",
       "27                                               [24467]  \n",
       "28                     [3063, 6248, 31054, 31056, 33495]  \n",
       "29     [26379, 26387, 26390, 26392, 26394, 26396, 264...  \n",
       "...                                                  ...  \n",
       "41691                 [2089, 12119, 20228, 34414, 35452]  \n",
       "41692                                             [1678]  \n",
       "41693              [3967, 4685, 4686, 4687, 6267, 32472]  \n",
       "41694                                            [33913]  \n",
       "41695                                            [11379]  \n",
       "41696                                            [28301]  \n",
       "41697                                            [31798]  \n",
       "41698                                             [4433]  \n",
       "41699                                            [29008]  \n",
       "41700                                            [33952]  \n",
       "41701                              [17771, 30032, 35354]  \n",
       "41702          [6223, 13048, 13090, 28938, 32086, 33732]  \n",
       "41703                              [10471, 10481, 10494]  \n",
       "41704                                             [5799]  \n",
       "41705           [5608, 8365, 26430, 29107, 29745, 32101]  \n",
       "41706                                            [32742]  \n",
       "41707                                     [11768, 14988]  \n",
       "41708  [10222, 21423, 22973, 23743, 28433, 28534, 288...  \n",
       "41709                                [663, 20501, 28528]  \n",
       "41710                                     [11388, 22237]  \n",
       "41711                                     [17627, 21215]  \n",
       "41712  [252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...  \n",
       "41713          [2330, 13923, 26586, 28177, 34236, 38583]  \n",
       "41714                              [12901, 37725, 37754]  \n",
       "41715                                     [19970, 19989]  \n",
       "41716                                     [11179, 28081]  \n",
       "41717                                            [18908]  \n",
       "41718                                             [4038]  \n",
       "41719                           [3941, 3974, 4023, 4666]  \n",
       "41720                                            [35509]  \n",
       "\n",
       "[41721 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_term=[]\n",
    "for i in range(len(dataframe)):\n",
    "    correct_term.append(dataframe.iloc[i,0].replace(\",\",\"\").replace(\"'\",\"\").replace('\"',\"\").replace('[',\"\").replace(']',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dataframe['correct_term']=correct_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>list_correct</th>\n",
       "      <th>correct_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'psychology',</td>\n",
       "      <td>[2300, 2337, 2786, 13505, 14583, 14707, 25248,...</td>\n",
       "      <td>[2300, 2337, 2786, 13505, 14583, 14707, 25248,...</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'entrant',</td>\n",
       "      <td>[3501, 22709]</td>\n",
       "      <td>[3501, 22709]</td>\n",
       "      <td>entrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'disfavor',</td>\n",
       "      <td>[31555]</td>\n",
       "      <td>[31555]</td>\n",
       "      <td>disfavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['attorney',</td>\n",
       "      <td>[14514, 21286]</td>\n",
       "      <td>[14514, 21286]</td>\n",
       "      <td>attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'visualization',</td>\n",
       "      <td>[1210]</td>\n",
       "      <td>[1210]</td>\n",
       "      <td>visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'flamed',</td>\n",
       "      <td>[7945]</td>\n",
       "      <td>[7945]</td>\n",
       "      <td>flamed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'aiding',</td>\n",
       "      <td>[15572, 19590, 21151, 21441, 23325, 23512]</td>\n",
       "      <td>[15572, 19590, 21151, 21441, 23325, 23512]</td>\n",
       "      <td>aiding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'symphony',</td>\n",
       "      <td>[935, 1089, 1999, 7504, 11491, 11494, 11498, 1...</td>\n",
       "      <td>[935, 1089, 1999, 7504, 11491, 11494, 11498, 1...</td>\n",
       "      <td>symphony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'1488',</td>\n",
       "      <td>[29364]</td>\n",
       "      <td>[29364]</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'lilacs',</td>\n",
       "      <td>[13822, 13850]</td>\n",
       "      <td>[13822, 13850]</td>\n",
       "      <td>lilacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['workers',</td>\n",
       "      <td>[12086]</td>\n",
       "      <td>[12086]</td>\n",
       "      <td>workers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['bmews',</td>\n",
       "      <td>[33698]</td>\n",
       "      <td>[33698]</td>\n",
       "      <td>bmews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'illinois',</td>\n",
       "      <td>[356, 12746, 12747, 15031, 16708, 21269, 21402...</td>\n",
       "      <td>[356, 12746, 12747, 15031, 16708, 21269, 21402...</td>\n",
       "      <td>illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'machines',</td>\n",
       "      <td>[2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...</td>\n",
       "      <td>[2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...</td>\n",
       "      <td>machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'toot',</td>\n",
       "      <td>[9629, 28659]</td>\n",
       "      <td>[9629, 28659]</td>\n",
       "      <td>toot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'sokolov',</td>\n",
       "      <td>[28696]</td>\n",
       "      <td>[28696]</td>\n",
       "      <td>sokolov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'alertly',</td>\n",
       "      <td>[18830]</td>\n",
       "      <td>[18830]</td>\n",
       "      <td>alertly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'lucretius',</td>\n",
       "      <td>[14994]</td>\n",
       "      <td>[14994]</td>\n",
       "      <td>lucretius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'glob-flakes',</td>\n",
       "      <td>[7304]</td>\n",
       "      <td>[7304]</td>\n",
       "      <td>glob-flakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'cuffs',</td>\n",
       "      <td>[9609, 36187]</td>\n",
       "      <td>[9609, 36187]</td>\n",
       "      <td>cuffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['sections',</td>\n",
       "      <td>[4678, 4690, 4694, 4717]</td>\n",
       "      <td>[4678, 4690, 4694, 4717]</td>\n",
       "      <td>sections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'occupy',</td>\n",
       "      <td>[2355, 3420, 8839, 11590, 13258, 13691, 28328,...</td>\n",
       "      <td>[2355, 3420, 8839, 11590, 13258, 13691, 28328,...</td>\n",
       "      <td>occupy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'accessions',</td>\n",
       "      <td>[35184]</td>\n",
       "      <td>[35184]</td>\n",
       "      <td>accessions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'imaginary',</td>\n",
       "      <td>[5915, 5920, 6559, 9271, 10064, 10066, 14908, ...</td>\n",
       "      <td>[5915, 5920, 6559, 9271, 10064, 10066, 14908, ...</td>\n",
       "      <td>imaginary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'absinthe',</td>\n",
       "      <td>[31512]</td>\n",
       "      <td>[31512]</td>\n",
       "      <td>absinthe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'souci',</td>\n",
       "      <td>[7388]</td>\n",
       "      <td>[7388]</td>\n",
       "      <td>souci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['prior',</td>\n",
       "      <td>[341, 2732, 15393, 15394, 22886, 34721, 35375]</td>\n",
       "      <td>[341, 2732, 15393, 15394, 22886, 34721, 35375]</td>\n",
       "      <td>prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'double-bogeyed',</td>\n",
       "      <td>[24467]</td>\n",
       "      <td>[24467]</td>\n",
       "      <td>double-bogeyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'progresses',</td>\n",
       "      <td>[3063, 6248, 31054, 31056, 33495]</td>\n",
       "      <td>[3063, 6248, 31054, 31056, 33495]</td>\n",
       "      <td>progresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>'autistic',</td>\n",
       "      <td>[26379, 26387, 26390, 26392, 26394, 26396, 264...</td>\n",
       "      <td>[26379, 26387, 26390, 26392, 26394, 26396, 264...</td>\n",
       "      <td>autistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41691</th>\n",
       "      <td>'encroachment',</td>\n",
       "      <td>[2089, 12119, 20228, 34414, 35452]</td>\n",
       "      <td>[2089, 12119, 20228, 34414, 35452]</td>\n",
       "      <td>encroachment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41692</th>\n",
       "      <td>'potentiality',</td>\n",
       "      <td>[1678]</td>\n",
       "      <td>[1678]</td>\n",
       "      <td>potentiality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41693</th>\n",
       "      <td>'filter',</td>\n",
       "      <td>[3967, 4685, 4686, 4687, 6267, 32472]</td>\n",
       "      <td>[3967, 4685, 4686, 4687, 6267, 32472]</td>\n",
       "      <td>filter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41694</th>\n",
       "      <td>'canals',</td>\n",
       "      <td>[33913]</td>\n",
       "      <td>[33913]</td>\n",
       "      <td>canals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>'tragically',</td>\n",
       "      <td>[11379]</td>\n",
       "      <td>[11379]</td>\n",
       "      <td>tragically</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>'cieca',</td>\n",
       "      <td>[28301]</td>\n",
       "      <td>[28301]</td>\n",
       "      <td>cieca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>'allot',</td>\n",
       "      <td>[31798]</td>\n",
       "      <td>[31798]</td>\n",
       "      <td>allot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>'protease',</td>\n",
       "      <td>[4433]</td>\n",
       "      <td>[4433]</td>\n",
       "      <td>protease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>'misleads',</td>\n",
       "      <td>[29008]</td>\n",
       "      <td>[29008]</td>\n",
       "      <td>misleads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41700</th>\n",
       "      <td>'arcaded',</td>\n",
       "      <td>[33952]</td>\n",
       "      <td>[33952]</td>\n",
       "      <td>arcaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41701</th>\n",
       "      <td>'proviso',</td>\n",
       "      <td>[17771, 30032, 35354]</td>\n",
       "      <td>[17771, 30032, 35354]</td>\n",
       "      <td>proviso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41702</th>\n",
       "      <td>'charts',</td>\n",
       "      <td>[6223, 13048, 13090, 28938, 32086, 33732]</td>\n",
       "      <td>[6223, 13048, 13090, 28938, 32086, 33732]</td>\n",
       "      <td>charts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41703</th>\n",
       "      <td>['digby',</td>\n",
       "      <td>[10471, 10481, 10494]</td>\n",
       "      <td>[10471, 10481, 10494]</td>\n",
       "      <td>digby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41704</th>\n",
       "      <td>'koop',</td>\n",
       "      <td>[5799]</td>\n",
       "      <td>[5799]</td>\n",
       "      <td>koop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41705</th>\n",
       "      <td>'bronze',</td>\n",
       "      <td>[5608, 8365, 26430, 29107, 29745, 32101]</td>\n",
       "      <td>[5608, 8365, 26430, 29107, 29745, 32101]</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41706</th>\n",
       "      <td>'tracers',</td>\n",
       "      <td>[32742]</td>\n",
       "      <td>[32742]</td>\n",
       "      <td>tracers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41707</th>\n",
       "      <td>'schelling',</td>\n",
       "      <td>[11768, 14988]</td>\n",
       "      <td>[11768, 14988]</td>\n",
       "      <td>schelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41708</th>\n",
       "      <td>'appearances',</td>\n",
       "      <td>[10222, 21423, 22973, 23743, 28433, 28534, 288...</td>\n",
       "      <td>[10222, 21423, 22973, 23743, 28433, 28534, 288...</td>\n",
       "      <td>appearances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41709</th>\n",
       "      <td>'acclaimed',</td>\n",
       "      <td>[663, 20501, 28528]</td>\n",
       "      <td>[663, 20501, 28528]</td>\n",
       "      <td>acclaimed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41710</th>\n",
       "      <td>'creditable',</td>\n",
       "      <td>[11388, 22237]</td>\n",
       "      <td>[11388, 22237]</td>\n",
       "      <td>creditable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41711</th>\n",
       "      <td>'blaine',</td>\n",
       "      <td>[17627, 21215]</td>\n",
       "      <td>[17627, 21215]</td>\n",
       "      <td>blaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41712</th>\n",
       "      <td>'volume',</td>\n",
       "      <td>[252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...</td>\n",
       "      <td>[252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...</td>\n",
       "      <td>volume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41713</th>\n",
       "      <td>'recalling',</td>\n",
       "      <td>[2330, 13923, 26586, 28177, 34236, 38583]</td>\n",
       "      <td>[2330, 13923, 26586, 28177, 34236, 38583]</td>\n",
       "      <td>recalling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41714</th>\n",
       "      <td>'booty',</td>\n",
       "      <td>[12901, 37725, 37754]</td>\n",
       "      <td>[12901, 37725, 37754]</td>\n",
       "      <td>booty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41715</th>\n",
       "      <td>['agnese',</td>\n",
       "      <td>[19970, 19989]</td>\n",
       "      <td>[19970, 19989]</td>\n",
       "      <td>agnese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41716</th>\n",
       "      <td>'admirably',</td>\n",
       "      <td>[11179, 28081]</td>\n",
       "      <td>[11179, 28081]</td>\n",
       "      <td>admirably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41717</th>\n",
       "      <td>['setting',</td>\n",
       "      <td>[18908]</td>\n",
       "      <td>[18908]</td>\n",
       "      <td>setting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41718</th>\n",
       "      <td>'lumps',</td>\n",
       "      <td>[4038]</td>\n",
       "      <td>[4038]</td>\n",
       "      <td>lumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41719</th>\n",
       "      <td>'dialyzed',</td>\n",
       "      <td>[3941, 3974, 4023, 4666]</td>\n",
       "      <td>[3941, 3974, 4023, 4666]</td>\n",
       "      <td>dialyzed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41720</th>\n",
       "      <td>'officielle',</td>\n",
       "      <td>[35509]</td>\n",
       "      <td>[35509]</td>\n",
       "      <td>officielle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41721 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                                                  1  \\\n",
       "0          'psychology',  [2300, 2337, 2786, 13505, 14583, 14707, 25248,...   \n",
       "1             'entrant',                                      [3501, 22709]   \n",
       "2            'disfavor',                                            [31555]   \n",
       "3           ['attorney',                                     [14514, 21286]   \n",
       "4       'visualization',                                             [1210]   \n",
       "5              'flamed',                                             [7945]   \n",
       "6              'aiding',         [15572, 19590, 21151, 21441, 23325, 23512]   \n",
       "7            'symphony',  [935, 1089, 1999, 7504, 11491, 11494, 11498, 1...   \n",
       "8                '1488',                                            [29364]   \n",
       "9              'lilacs',                                     [13822, 13850]   \n",
       "10           ['workers',                                            [12086]   \n",
       "11             ['bmews',                                            [33698]   \n",
       "12           'illinois',  [356, 12746, 12747, 15031, 16708, 21269, 21402...   \n",
       "13           'machines',  [2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...   \n",
       "14               'toot',                                      [9629, 28659]   \n",
       "15            'sokolov',                                            [28696]   \n",
       "16            'alertly',                                            [18830]   \n",
       "17          'lucretius',                                            [14994]   \n",
       "18        'glob-flakes',                                             [7304]   \n",
       "19              'cuffs',                                      [9609, 36187]   \n",
       "20          ['sections',                           [4678, 4690, 4694, 4717]   \n",
       "21             'occupy',  [2355, 3420, 8839, 11590, 13258, 13691, 28328,...   \n",
       "22         'accessions',                                            [35184]   \n",
       "23          'imaginary',  [5915, 5920, 6559, 9271, 10064, 10066, 14908, ...   \n",
       "24           'absinthe',                                            [31512]   \n",
       "25              'souci',                                             [7388]   \n",
       "26             ['prior',     [341, 2732, 15393, 15394, 22886, 34721, 35375]   \n",
       "27     'double-bogeyed',                                            [24467]   \n",
       "28         'progresses',                  [3063, 6248, 31054, 31056, 33495]   \n",
       "29           'autistic',  [26379, 26387, 26390, 26392, 26394, 26396, 264...   \n",
       "...                  ...                                                ...   \n",
       "41691    'encroachment',                 [2089, 12119, 20228, 34414, 35452]   \n",
       "41692    'potentiality',                                             [1678]   \n",
       "41693          'filter',              [3967, 4685, 4686, 4687, 6267, 32472]   \n",
       "41694          'canals',                                            [33913]   \n",
       "41695      'tragically',                                            [11379]   \n",
       "41696           'cieca',                                            [28301]   \n",
       "41697           'allot',                                            [31798]   \n",
       "41698        'protease',                                             [4433]   \n",
       "41699        'misleads',                                            [29008]   \n",
       "41700         'arcaded',                                            [33952]   \n",
       "41701         'proviso',                              [17771, 30032, 35354]   \n",
       "41702          'charts',          [6223, 13048, 13090, 28938, 32086, 33732]   \n",
       "41703          ['digby',                              [10471, 10481, 10494]   \n",
       "41704            'koop',                                             [5799]   \n",
       "41705          'bronze',           [5608, 8365, 26430, 29107, 29745, 32101]   \n",
       "41706         'tracers',                                            [32742]   \n",
       "41707       'schelling',                                     [11768, 14988]   \n",
       "41708     'appearances',  [10222, 21423, 22973, 23743, 28433, 28534, 288...   \n",
       "41709       'acclaimed',                                [663, 20501, 28528]   \n",
       "41710      'creditable',                                     [11388, 22237]   \n",
       "41711          'blaine',                                     [17627, 21215]   \n",
       "41712          'volume',  [252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...   \n",
       "41713       'recalling',          [2330, 13923, 26586, 28177, 34236, 38583]   \n",
       "41714           'booty',                              [12901, 37725, 37754]   \n",
       "41715         ['agnese',                                     [19970, 19989]   \n",
       "41716       'admirably',                                     [11179, 28081]   \n",
       "41717        ['setting',                                            [18908]   \n",
       "41718           'lumps',                                             [4038]   \n",
       "41719        'dialyzed',                           [3941, 3974, 4023, 4666]   \n",
       "41720      'officielle',                                            [35509]   \n",
       "\n",
       "                                            list_correct    correct_term  \n",
       "0      [2300, 2337, 2786, 13505, 14583, 14707, 25248,...      psychology  \n",
       "1                                          [3501, 22709]         entrant  \n",
       "2                                                [31555]        disfavor  \n",
       "3                                         [14514, 21286]        attorney  \n",
       "4                                                 [1210]   visualization  \n",
       "5                                                 [7945]          flamed  \n",
       "6             [15572, 19590, 21151, 21441, 23325, 23512]          aiding  \n",
       "7      [935, 1089, 1999, 7504, 11491, 11494, 11498, 1...        symphony  \n",
       "8                                                [29364]            1488  \n",
       "9                                         [13822, 13850]          lilacs  \n",
       "10                                               [12086]         workers  \n",
       "11                                               [33698]           bmews  \n",
       "12     [356, 12746, 12747, 15031, 16708, 21269, 21402...        illinois  \n",
       "13     [2416, 2429, 2440, 2441, 2448, 2453, 2513, 115...        machines  \n",
       "14                                         [9629, 28659]            toot  \n",
       "15                                               [28696]         sokolov  \n",
       "16                                               [18830]         alertly  \n",
       "17                                               [14994]       lucretius  \n",
       "18                                                [7304]     glob-flakes  \n",
       "19                                         [9609, 36187]           cuffs  \n",
       "20                              [4678, 4690, 4694, 4717]        sections  \n",
       "21     [2355, 3420, 8839, 11590, 13258, 13691, 28328,...          occupy  \n",
       "22                                               [35184]      accessions  \n",
       "23     [5915, 5920, 6559, 9271, 10064, 10066, 14908, ...       imaginary  \n",
       "24                                               [31512]        absinthe  \n",
       "25                                                [7388]           souci  \n",
       "26        [341, 2732, 15393, 15394, 22886, 34721, 35375]           prior  \n",
       "27                                               [24467]  double-bogeyed  \n",
       "28                     [3063, 6248, 31054, 31056, 33495]      progresses  \n",
       "29     [26379, 26387, 26390, 26392, 26394, 26396, 264...        autistic  \n",
       "...                                                  ...             ...  \n",
       "41691                 [2089, 12119, 20228, 34414, 35452]    encroachment  \n",
       "41692                                             [1678]    potentiality  \n",
       "41693              [3967, 4685, 4686, 4687, 6267, 32472]          filter  \n",
       "41694                                            [33913]          canals  \n",
       "41695                                            [11379]      tragically  \n",
       "41696                                            [28301]           cieca  \n",
       "41697                                            [31798]           allot  \n",
       "41698                                             [4433]        protease  \n",
       "41699                                            [29008]        misleads  \n",
       "41700                                            [33952]         arcaded  \n",
       "41701                              [17771, 30032, 35354]         proviso  \n",
       "41702          [6223, 13048, 13090, 28938, 32086, 33732]          charts  \n",
       "41703                              [10471, 10481, 10494]           digby  \n",
       "41704                                             [5799]            koop  \n",
       "41705           [5608, 8365, 26430, 29107, 29745, 32101]          bronze  \n",
       "41706                                            [32742]         tracers  \n",
       "41707                                     [11768, 14988]       schelling  \n",
       "41708  [10222, 21423, 22973, 23743, 28433, 28534, 288...     appearances  \n",
       "41709                                [663, 20501, 28528]       acclaimed  \n",
       "41710                                     [11388, 22237]      creditable  \n",
       "41711                                     [17627, 21215]          blaine  \n",
       "41712  [252, 913, 3011, 3314, 3315, 3318, 3320, 3359,...          volume  \n",
       "41713          [2330, 13923, 26586, 28177, 34236, 38583]       recalling  \n",
       "41714                              [12901, 37725, 37754]           booty  \n",
       "41715                                     [19970, 19989]          agnese  \n",
       "41716                                     [11179, 28081]       admirably  \n",
       "41717                                            [18908]         setting  \n",
       "41718                                             [4038]           lumps  \n",
       "41719                           [3941, 3974, 4023, 4666]        dialyzed  \n",
       "41720                                            [35509]      officielle  \n",
       "\n",
       "[41721 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2 = pd.read_json(\"export_file.json\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_term2=[]\n",
    "for i in range(len(dataframe2)):\n",
    "    correct_term2.append(dataframe2.iloc[i,0].replace(\",\",\"\").replace(\"'\",\"\").replace('\"',\"\").replace('[',\"\").replace(']',\"\"))\n",
    "dataframe2['correct_term']=correct_term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>correct_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'mounds',</td>\n",
       "      <td>[4098]</td>\n",
       "      <td>mounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'vulnerability',</td>\n",
       "      <td>[13638, 13639, 13640, 30648, 30685, 30686]</td>\n",
       "      <td>vulnerability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'outlying',</td>\n",
       "      <td>[17462, 26925]</td>\n",
       "      <td>outlying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'delegated',</td>\n",
       "      <td>[16894, 34405, 35521]</td>\n",
       "      <td>delegated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'previously',</td>\n",
       "      <td>[160, 1433, 2007, 3144, 3286, 3766, 3919, 4751...</td>\n",
       "      <td>previously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'accelerate',</td>\n",
       "      <td>[3564, 4468, 26313, 30037]</td>\n",
       "      <td>accelerate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'casals',</td>\n",
       "      <td>[23876]</td>\n",
       "      <td>casals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'prognosis',</td>\n",
       "      <td>[37087]</td>\n",
       "      <td>prognosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'clue',</td>\n",
       "      <td>[1297, 2800, 4791, 6589, 6695, 14196, 14381, 2...</td>\n",
       "      <td>clue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'high-class',</td>\n",
       "      <td>[35929]</td>\n",
       "      <td>high-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'insecticide',</td>\n",
       "      <td>[32908]</td>\n",
       "      <td>insecticide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'grin',</td>\n",
       "      <td>[699, 12905, 17407, 18549, 18732, 26230, 28065...</td>\n",
       "      <td>grin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'agglutinins',</td>\n",
       "      <td>[3909, 3986]</td>\n",
       "      <td>agglutinins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'friar',</td>\n",
       "      <td>[28980]</td>\n",
       "      <td>friar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'tory',</td>\n",
       "      <td>[2742, 34150, 34151]</td>\n",
       "      <td>tory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'versed',</td>\n",
       "      <td>[24272]</td>\n",
       "      <td>versed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'pianists',</td>\n",
       "      <td>[1960, 23842]</td>\n",
       "      <td>pianists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'softened',</td>\n",
       "      <td>[10671, 23341, 31581, 33814]</td>\n",
       "      <td>softened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'equipped',</td>\n",
       "      <td>[2625, 3599, 3604, 3607, 3702, 4684, 6221, 117...</td>\n",
       "      <td>equipped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'provisons',</td>\n",
       "      <td>[15163]</td>\n",
       "      <td>provisons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>'excellence',</td>\n",
       "      <td>[13912, 22415, 22417, 24234, 24235, 24244, 281...</td>\n",
       "      <td>excellence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'doings',</td>\n",
       "      <td>[5897, 21477]</td>\n",
       "      <td>doings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'buckled',</td>\n",
       "      <td>[38191]</td>\n",
       "      <td>buckled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'surprising',</td>\n",
       "      <td>[2161, 4153, 5770, 5890, 5891, 9629, 14309, 14...</td>\n",
       "      <td>surprising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'invaded',</td>\n",
       "      <td>[4646, 11330, 12901, 24389, 27090, 33917]</td>\n",
       "      <td>invaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'coalesces',</td>\n",
       "      <td>[25378]</td>\n",
       "      <td>coalesces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'isothermal',</td>\n",
       "      <td>[3368]</td>\n",
       "      <td>isothermal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'differentiable',</td>\n",
       "      <td>[4920, 4921, 4925]</td>\n",
       "      <td>differentiable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>['none',</td>\n",
       "      <td>[1914, 10184, 17552, 18098, 25162, 25710, 2979...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>'300000',</td>\n",
       "      <td>[142, 14782, 15883, 25947, 26706, 30700]</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41691</th>\n",
       "      <td>'chartres',</td>\n",
       "      <td>[13761]</td>\n",
       "      <td>chartres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41692</th>\n",
       "      <td>'rubdown',</td>\n",
       "      <td>[32276]</td>\n",
       "      <td>rubdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41693</th>\n",
       "      <td>'tangency',</td>\n",
       "      <td>[35237, 35249, 35251]</td>\n",
       "      <td>tangency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41694</th>\n",
       "      <td>'rifled',</td>\n",
       "      <td>[31430]</td>\n",
       "      <td>rifled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>'absolutely',</td>\n",
       "      <td>[1531, 2632, 2863, 2871, 2877, 5512, 5525, 554...</td>\n",
       "      <td>absolutely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>'russ',</td>\n",
       "      <td>[276, 18808, 18812, 18820, 18836, 18851, 18856...</td>\n",
       "      <td>russ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>'anterior',</td>\n",
       "      <td>[4452, 4469, 4772, 33204, 33208]</td>\n",
       "      <td>anterior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>'asymptotically',</td>\n",
       "      <td>[3332]</td>\n",
       "      <td>asymptotically</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>'whitfield',</td>\n",
       "      <td>[354]</td>\n",
       "      <td>whitfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41700</th>\n",
       "      <td>'development',</td>\n",
       "      <td>[194, 970, 1439, 1659, 1745, 1773, 1783, 1792,...</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41701</th>\n",
       "      <td>'moune',</td>\n",
       "      <td>[20887]</td>\n",
       "      <td>moune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41702</th>\n",
       "      <td>'imbroglio',</td>\n",
       "      <td>[24907]</td>\n",
       "      <td>imbroglio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41703</th>\n",
       "      <td>'bruno',</td>\n",
       "      <td>[34054]</td>\n",
       "      <td>bruno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41704</th>\n",
       "      <td>'defeat',</td>\n",
       "      <td>[2740, 5224, 5240, 13210, 13221, 13256, 13702,...</td>\n",
       "      <td>defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41705</th>\n",
       "      <td>'pouch',</td>\n",
       "      <td>[9001]</td>\n",
       "      <td>pouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41706</th>\n",
       "      <td>'article',</td>\n",
       "      <td>[1572, 1573, 1585, 7884, 11640, 11836, 15180, ...</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41707</th>\n",
       "      <td>'algebra',</td>\n",
       "      <td>[4917, 4930]</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41708</th>\n",
       "      <td>'treasurer',</td>\n",
       "      <td>[124, 5744, 5792, 5874, 20529, 21481, 21773, 2...</td>\n",
       "      <td>treasurer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41709</th>\n",
       "      <td>'twirling',</td>\n",
       "      <td>[2494, 10682, 34328]</td>\n",
       "      <td>twirling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41710</th>\n",
       "      <td>'hurrays',</td>\n",
       "      <td>[38884, 38887, 38892]</td>\n",
       "      <td>hurrays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41711</th>\n",
       "      <td>'clean-shaven',</td>\n",
       "      <td>[9044]</td>\n",
       "      <td>clean-shaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41712</th>\n",
       "      <td>'kroening',</td>\n",
       "      <td>[31204]</td>\n",
       "      <td>kroening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41713</th>\n",
       "      <td>'micrometeoritic',</td>\n",
       "      <td>[3691, 3715]</td>\n",
       "      <td>micrometeoritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41714</th>\n",
       "      <td>'sweethearts',</td>\n",
       "      <td>[12856]</td>\n",
       "      <td>sweethearts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41715</th>\n",
       "      <td>'grudgingly',</td>\n",
       "      <td>[19434, 27915, 37235, 37821, 37928]</td>\n",
       "      <td>grudgingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41716</th>\n",
       "      <td>'coup',</td>\n",
       "      <td>[13289, 21134, 25476]</td>\n",
       "      <td>coup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41717</th>\n",
       "      <td>'ridiculously',</td>\n",
       "      <td>[18968, 26327]</td>\n",
       "      <td>ridiculously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41718</th>\n",
       "      <td>'incidence',</td>\n",
       "      <td>[4310, 11840, 11848, 11849, 11930, 35501]</td>\n",
       "      <td>incidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41719</th>\n",
       "      <td>'side',</td>\n",
       "      <td>[436, 505, 677, 694, 942, 987, 1207, 1397, 153...</td>\n",
       "      <td>side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41720</th>\n",
       "      <td>'didn',</td>\n",
       "      <td>[19136]</td>\n",
       "      <td>didn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0                                                  1  \\\n",
       "0               'mounds',                                             [4098]   \n",
       "1        'vulnerability',         [13638, 13639, 13640, 30648, 30685, 30686]   \n",
       "2             'outlying',                                     [17462, 26925]   \n",
       "3            'delegated',                              [16894, 34405, 35521]   \n",
       "4           'previously',  [160, 1433, 2007, 3144, 3286, 3766, 3919, 4751...   \n",
       "5           'accelerate',                         [3564, 4468, 26313, 30037]   \n",
       "6               'casals',                                            [23876]   \n",
       "7            'prognosis',                                            [37087]   \n",
       "8                 'clue',  [1297, 2800, 4791, 6589, 6695, 14196, 14381, 2...   \n",
       "9           'high-class',                                            [35929]   \n",
       "10         'insecticide',                                            [32908]   \n",
       "11                'grin',  [699, 12905, 17407, 18549, 18732, 26230, 28065...   \n",
       "12         'agglutinins',                                       [3909, 3986]   \n",
       "13               'friar',                                            [28980]   \n",
       "14                'tory',                               [2742, 34150, 34151]   \n",
       "15              'versed',                                            [24272]   \n",
       "16            'pianists',                                      [1960, 23842]   \n",
       "17            'softened',                       [10671, 23341, 31581, 33814]   \n",
       "18            'equipped',  [2625, 3599, 3604, 3607, 3702, 4684, 6221, 117...   \n",
       "19           'provisons',                                            [15163]   \n",
       "20          'excellence',  [13912, 22415, 22417, 24234, 24235, 24244, 281...   \n",
       "21              'doings',                                      [5897, 21477]   \n",
       "22             'buckled',                                            [38191]   \n",
       "23          'surprising',  [2161, 4153, 5770, 5890, 5891, 9629, 14309, 14...   \n",
       "24             'invaded',          [4646, 11330, 12901, 24389, 27090, 33917]   \n",
       "25           'coalesces',                                            [25378]   \n",
       "26          'isothermal',                                             [3368]   \n",
       "27      'differentiable',                                 [4920, 4921, 4925]   \n",
       "28               ['none',  [1914, 10184, 17552, 18098, 25162, 25710, 2979...   \n",
       "29              '300000',           [142, 14782, 15883, 25947, 26706, 30700]   \n",
       "...                   ...                                                ...   \n",
       "41691         'chartres',                                            [13761]   \n",
       "41692          'rubdown',                                            [32276]   \n",
       "41693         'tangency',                              [35237, 35249, 35251]   \n",
       "41694           'rifled',                                            [31430]   \n",
       "41695       'absolutely',  [1531, 2632, 2863, 2871, 2877, 5512, 5525, 554...   \n",
       "41696             'russ',  [276, 18808, 18812, 18820, 18836, 18851, 18856...   \n",
       "41697         'anterior',                   [4452, 4469, 4772, 33204, 33208]   \n",
       "41698   'asymptotically',                                             [3332]   \n",
       "41699        'whitfield',                                              [354]   \n",
       "41700      'development',  [194, 970, 1439, 1659, 1745, 1773, 1783, 1792,...   \n",
       "41701            'moune',                                            [20887]   \n",
       "41702        'imbroglio',                                            [24907]   \n",
       "41703            'bruno',                                            [34054]   \n",
       "41704           'defeat',  [2740, 5224, 5240, 13210, 13221, 13256, 13702,...   \n",
       "41705            'pouch',                                             [9001]   \n",
       "41706          'article',  [1572, 1573, 1585, 7884, 11640, 11836, 15180, ...   \n",
       "41707          'algebra',                                       [4917, 4930]   \n",
       "41708        'treasurer',  [124, 5744, 5792, 5874, 20529, 21481, 21773, 2...   \n",
       "41709         'twirling',                               [2494, 10682, 34328]   \n",
       "41710          'hurrays',                              [38884, 38887, 38892]   \n",
       "41711     'clean-shaven',                                             [9044]   \n",
       "41712         'kroening',                                            [31204]   \n",
       "41713  'micrometeoritic',                                       [3691, 3715]   \n",
       "41714      'sweethearts',                                            [12856]   \n",
       "41715       'grudgingly',                [19434, 27915, 37235, 37821, 37928]   \n",
       "41716             'coup',                              [13289, 21134, 25476]   \n",
       "41717     'ridiculously',                                     [18968, 26327]   \n",
       "41718        'incidence',          [4310, 11840, 11848, 11849, 11930, 35501]   \n",
       "41719             'side',  [436, 505, 677, 694, 942, 987, 1207, 1397, 153...   \n",
       "41720             'didn',                                            [19136]   \n",
       "\n",
       "          correct_term  \n",
       "0               mounds  \n",
       "1        vulnerability  \n",
       "2             outlying  \n",
       "3            delegated  \n",
       "4           previously  \n",
       "5           accelerate  \n",
       "6               casals  \n",
       "7            prognosis  \n",
       "8                 clue  \n",
       "9           high-class  \n",
       "10         insecticide  \n",
       "11                grin  \n",
       "12         agglutinins  \n",
       "13               friar  \n",
       "14                tory  \n",
       "15              versed  \n",
       "16            pianists  \n",
       "17            softened  \n",
       "18            equipped  \n",
       "19           provisons  \n",
       "20          excellence  \n",
       "21              doings  \n",
       "22             buckled  \n",
       "23          surprising  \n",
       "24             invaded  \n",
       "25           coalesces  \n",
       "26          isothermal  \n",
       "27      differentiable  \n",
       "28                none  \n",
       "29              300000  \n",
       "...                ...  \n",
       "41691         chartres  \n",
       "41692          rubdown  \n",
       "41693         tangency  \n",
       "41694           rifled  \n",
       "41695       absolutely  \n",
       "41696             russ  \n",
       "41697         anterior  \n",
       "41698   asymptotically  \n",
       "41699        whitfield  \n",
       "41700      development  \n",
       "41701            moune  \n",
       "41702        imbroglio  \n",
       "41703            bruno  \n",
       "41704           defeat  \n",
       "41705            pouch  \n",
       "41706          article  \n",
       "41707          algebra  \n",
       "41708        treasurer  \n",
       "41709         twirling  \n",
       "41710          hurrays  \n",
       "41711     clean-shaven  \n",
       "41712         kroening  \n",
       "41713  micrometeoritic  \n",
       "41714      sweethearts  \n",
       "41715       grudgingly  \n",
       "41716             coup  \n",
       "41717     ridiculously  \n",
       "41718        incidence  \n",
       "41719             side  \n",
       "41720             didn  \n",
       "\n",
       "[41721 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe2#.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cdi=pd.read_csv(\"cdi_WS_wordNetSenses.csv\")\n",
    "adj=pd.read_excel(\"Adj_senses.xlsx\")\n",
    "n=pd.read_excel(\"n_senses.xlsx\")\n",
    "r=pd.read_excel(\"r_senses.xlsx\")\n",
    "v=pd.read_excel(\"v_senses.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>sense_index</th>\n",
       "      <th>name</th>\n",
       "      <th>lexname</th>\n",
       "      <th>pos</th>\n",
       "      <th>definition</th>\n",
       "      <th>examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>vroom</td>\n",
       "      <td>0</td>\n",
       "      <td>vroom.n.01</td>\n",
       "      <td>noun.event</td>\n",
       "      <td>n</td>\n",
       "      <td>the roaring sound made by a motor that is runn...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vroom</td>\n",
       "      <td>1</td>\n",
       "      <td>vroom.v.01</td>\n",
       "      <td>verb.communication</td>\n",
       "      <td>v</td>\n",
       "      <td>make a loud, roaring sound, as of a car engine...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>duck</td>\n",
       "      <td>0</td>\n",
       "      <td>duck.n.01</td>\n",
       "      <td>noun.animal</td>\n",
       "      <td>n</td>\n",
       "      <td>small wild or domesticated web-footed broad-bi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>duck</td>\n",
       "      <td>1</td>\n",
       "      <td>duck.n.02</td>\n",
       "      <td>noun.quantity</td>\n",
       "      <td>n</td>\n",
       "      <td>(cricket) a score of nothing by a batsman</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>duck</td>\n",
       "      <td>2</td>\n",
       "      <td>duck.n.03</td>\n",
       "      <td>noun.food</td>\n",
       "      <td>n</td>\n",
       "      <td>flesh of a duck (domestic or wild)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   word  sense_index        name             lexname pos  \\\n",
       "0           0  vroom            0  vroom.n.01          noun.event   n   \n",
       "1           1  vroom            1  vroom.v.01  verb.communication   v   \n",
       "2           0   duck            0   duck.n.01         noun.animal   n   \n",
       "3           1   duck            1   duck.n.02       noun.quantity   n   \n",
       "4           2   duck            2   duck.n.03           noun.food   n   \n",
       "\n",
       "                                          definition examples  \n",
       "0  the roaring sound made by a motor that is runn...      NaN  \n",
       "1  make a loud, roaring sound, as of a car engine...      NaN  \n",
       "2  small wild or domesticated web-footed broad-bi...      NaN  \n",
       "3          (cricket) a score of nothing by a batsman      NaN  \n",
       "4                 flesh of a duck (domestic or wild)      NaN  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5362, 8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'duck', [7670, 10491, 18734, 19079, 20087]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-acf4c50ba81e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#             print(semcor.sents()[j])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;34m'duck.v.01'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msemcor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'both'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msemcor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\collections.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[1;31m# Use iterate_from to extract it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index out of range'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\util.py\u001b[0m in \u001b[0;36miterate_from\u001b[1;34m(self, start_tok)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# Get everything we can from this piece.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpiece\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_tok\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\util.py\u001b[0m in \u001b[0;36miterate_from\u001b[1;34m(self, start_tok)\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[0;32m    298\u001b[0m                 \u001b[1;34m'block reader %s() should return list or tuple.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\xmldocs.py\u001b[0m in \u001b[0;36mread_block\u001b[1;34m(self, stream, tagspec, elt_handler)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                   elt.encode('ascii', 'xmlcharrefreplace')),\n\u001b[0;32m    391\u001b[0m                             context)\n\u001b[1;32m--> 392\u001b[1;33m                 for (elt, context) in elts]\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\xmldocs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                   elt.encode('ascii', 'xmlcharrefreplace')),\n\u001b[0;32m    391\u001b[0m                             context)\n\u001b[1;32m--> 392\u001b[1;33m                 for (elt, context) in elts]\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36mhandle_elt\u001b[1;34m(self, elt, context)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_elt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36mhandle_sent\u001b[1;34m(self, elt)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'wf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'punc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 \u001b[0mitm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unit\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                     \u001b[0msent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36mhandle_word\u001b[1;34m(self, elt)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSemcorCorpusReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pos_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sem_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wordnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\semcor.py\u001b[0m in \u001b[0;36m_word\u001b[1;34m(xmlword, unit, pos_tag, sem_tag, wordnet)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msensenum\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                         \u001b[0msense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_from_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msense_key\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Lemma object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                         \u001b[1;31m# cannot retrieve the wordnet.Lemma object. possible reasons:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36mlemma_from_key\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \u001b[1;31m# Find the synset for the lemma.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1273\u001b[1;33m         \u001b[0msynset_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_binary_search_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key_synset_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msynset_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mWordNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No synset found for key %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\util.py\u001b[0m in \u001b[0;36mbinary_search_file\u001b[1;34m(file, key, cache, cacheDepth)\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m                 \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiddle\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmiddle\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\dataX\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mseek\u001b[1;34m(self, offset, whence)\u001b[0m\n\u001b[0;32m   1276\u001b[0m                              \u001b[1;34m'SeekableUnicodeStreamReader -- consider '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m                              'using char_seek_forward() instead.')\n\u001b[1;32m-> 1278\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinebuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbytebuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(dataframe2)):\n",
    "    if 'duck' == dataframe2['correct_term'][i]:\n",
    "        print(dataframe2.iloc[i,0], dataframe2.iloc[i,1])\n",
    "        for j in dataframe2.iloc[i,1]:\n",
    "#             print(semcor.sents()[j])\n",
    "            if 'duck.v.01' in str(semcor.tagged_sents(tag='both')[j]):\n",
    "                print(semcor.sents()[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataX Python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
